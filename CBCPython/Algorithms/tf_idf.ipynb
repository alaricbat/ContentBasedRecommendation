{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1633e6",
   "metadata": {},
   "source": [
    "## Vector Space Model\n",
    "\n",
    "Represents documents and terms as vectors in a multi-dimensional space.\n",
    "\n",
    "Each dimensional corresponds to a unique term in the entire corpus of documents.\n",
    "\\\n",
    "&nbsp;\n",
    "\n",
    "<img src=\"../Resource/Images/vector_space_model.jpg\" alt=\"Vecto Space Model\" style=\"width:400px;\"/>\n",
    "\n",
    "\n",
    "<h5><b>Document-Term Matrix (DTM)</b><br></h5>\n",
    "Rows in this matrix represent documents, columns represent terms (words or phrases).<br>\n",
    "\n",
    "<b>Example:</b> <br>\n",
    "<ul>\n",
    "    <li><b>Doc1: </b>\"I love data\"</li>\n",
    "    <li><b>Doc2: </b>\"I love AI and data\"</li>\n",
    "    <li><b>Doc3: </b>\"AI is the future\"</li>\n",
    "</ul>\n",
    "<br>\n",
    "<b>Corresponding Matrix:</b> <br><br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>I</th>\n",
    "        <th>love</th>\n",
    "        <th>data</th>\n",
    "        <th>AI</th>\n",
    "        <th>future</th>\n",
    "    </tr>\n",
    "        <th>Doc1</th>\n",
    "        <th>1</th>\n",
    "        <th>1</th>\n",
    "        <th>1</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "    </tr>\n",
    "        </tr>\n",
    "        <th>Doc2</th>\n",
    "        <th>1</th>\n",
    "        <th>1</th>\n",
    "        <th>1</th>\n",
    "        <th>1</th>\n",
    "        <th>0</th>\n",
    "    </tr>\n",
    "        </tr>\n",
    "        <th>Doc3</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "        <th>1</th>\n",
    "        <th>1</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h5><b>Term Frequency - Inverse Document Frequency (TF-IDF) (*)</b><br></h5>\n",
    "A measure that reflects the importance of a term within a document relative to its importance across all documents in the corpus. It helps in highlighting important terms while downplaying common terms.<br>\n",
    "<br>\n",
    "<div><b>Term Frequency (TF):</b> How often a word appears in a document.</div>\n",
    "<br>\n",
    "<div>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>TF(t,d) = (Number of times term t appears in document d) / (Total number of terms in document d)</th>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "<br>\n",
    "<div><b>Inverse Document Frequency (IDF):</b> How rare or unique a word is across all documents.</div>\n",
    "<br>\n",
    "<div>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>TF(t,d) = LOG[(Total number of documents in corpus D) / (Number of documents containing term t)]</th>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "<br>\n",
    "<div><b>Calculate TD-IDF.</div>\n",
    "<br>\n",
    "<div>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>TF-IDF(t, d, D) = TF(t, d) x IDF(t, D)</th>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<b>Corresponding Matrix (TF-IDF):</b> <br><br>\n",
    "<br>\n",
    "<div><b>Step 1:</b></div>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>I</th>\n",
    "        <th>love</th>\n",
    "        <th>data</th>\n",
    "        <th>AI</th>\n",
    "        <th>future</th>\n",
    "    </tr>\n",
    "        <th>Doc1</th>\n",
    "        <th>[(1/3) x log(3/2)]</th>\n",
    "        <th>[(1/3) x log(3/2)]</th>\n",
    "        <th>[(1/3) x log(3/2)]</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "    </tr>\n",
    "        </tr>\n",
    "        <th>Doc2</th>\n",
    "        <th>[(1/5) x log(3/2)]</th>\n",
    "        <th>[(1/5) x log(3/2)]</th>\n",
    "        <th>[(1/5) x log(3/2)]</th>\n",
    "        <th>[(1/5) x log(3/2)]</th>\n",
    "        <th>0</th>\n",
    "    </tr>\n",
    "        </tr>\n",
    "        <th>Doc3</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "        <th>[(1/4) x log(3/2)]</th>\n",
    "        <th>[(1/4) x log(3/1)] </th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "<div><b>Step 2: Final Result</b></div>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>I</th>\n",
    "        <th>love</th>\n",
    "        <th>data</th>\n",
    "        <th>AI</th>\n",
    "        <th>future</th>\n",
    "    </tr>\n",
    "        <th>Doc1</th>\n",
    "        <th>0.058</th>\n",
    "        <th>0.058</th>\n",
    "        <th>0.058</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "    </tr>\n",
    "        </tr>\n",
    "        <th>Doc2</th>\n",
    "        <th>0.035</th>\n",
    "        <th>0.035</th>\n",
    "        <th>0.035</th>\n",
    "        <th>0.035</th>\n",
    "        <th>0</th>\n",
    "    </tr>\n",
    "        </tr>\n",
    "        <th>Doc3</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "        <th>0</th>\n",
    "        <th>0.044</th>\n",
    "        <th>0.119</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h5><b>Vectorization</b><br></h5>\n",
    "<br>\n",
    "<div>After applying TF-IDF, each document becomes a <b>vector</b> - essentially a list of numbers - in a high-dimensional space.</div>\n",
    "<br>\n",
    "<ul>\n",
    "    <li>Each dimension in this space represents a unique word (term) from the entire collection of documents.</li>\n",
    "    <li>Each document is a point (vector) in this space, where the value in each dimension shows how important that term is in the document.</li>\n",
    "</ul>\n",
    "<br>\n",
    "<div><b>Unique terms in the corpus:</b></div>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Doc1</th>\n",
    "        <th>[0.058, 0.058, 0.058, 0, 0]</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Doc2</th>\n",
    "        <th>[0.035, 0.035, 0.035, 0.035, 0]</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Doc3</th>\n",
    "        <th>[0, 0, 0, 0.044, 0.119]</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h5><b>Cosine Similarity</b><br></h5>\n",
    "\n",
    "<div>\n",
    "    <img src=\"../Resource/Images/cosin_formula.png\" alt=\"Vecto Space Model\" style=\"width:400px;\"/>\n",
    "</div>\n",
    "\n",
    "<ul>\n",
    "    <li>It measures the cosine of the angle between two vectors in a high-dimensional space.</li>\n",
    "    <li>It doesn't care about the magnitude of the vectors â€” just their direction.</li>\n",
    "    <li>This is ideal for text, because documents can be different lengths but still have similar content.</li>\n",
    "</ul>\n",
    "\n",
    "<div><b>Interpretation of Cosine Similarity Scores</b></div>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Similarity Score</th>\n",
    "        <th>Exactly the same direction (identical content)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>0.8 - 1.0</th>\n",
    "        <th>Highly similar</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>0.5 - 0.8</th>\n",
    "        <th>Moderately similar</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>0.2 - 0.5</th>\n",
    "        <th>Slightly similar</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>0.0</th>\n",
    "        <th>No similarity</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>< 0.0</th>\n",
    "        <th>Opposite meaning (rare in text analysis)</th>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1835fc",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488103dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Sample documents \n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A brown dog chased the fox.\",\n",
    "    \"The dog is lazy.\"\n",
    "]\n",
    "\n",
    "#Sample query\n",
    "query = \"brown dog\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c645bf",
   "metadata": {},
   "source": [
    "### Tokenize and preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc50808c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tanchutat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_documents = [word_tokenize(doc.lower()) for doc in documents]\n",
    "tokenized_query = word_tokenize(query.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4dc30",
   "metadata": {},
   "source": [
    "### Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "544f5ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the quick brown fox jumps over the lazy dog .',\n",
       " 'a brown dog chased the fox .',\n",
       " 'the dog is lazy .']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_documents = [' '.join(doc) for doc in tokenized_documents]\n",
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca11650c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29877806, 0.        , 0.23202782, 0.29877806, 0.        ,\n",
       "        0.39285725, 0.29877806, 0.39285725, 0.39285725, 0.46405564],\n",
       "       [0.45014501, 0.59188659, 0.34957775, 0.45014501, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34957775],\n",
       "       [0.        , 0.        , 0.39148397, 0.        , 0.66283998,\n",
       "        0.        , 0.50410689, 0.        , 0.        , 0.39148397]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_documents)\n",
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3df99f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column [brown]: '1.2876820724517808'\n",
      "Column [chased]: '1.6931471805599454'\n",
      "Column [dog]: '1.0'\n",
      "Column [fox]: '1.2876820724517808'\n",
      "Column [is]: '1.6931471805599454'\n",
      "Column [jumps]: '1.6931471805599454'\n",
      "Column [lazy]: '1.2876820724517808'\n",
      "Column [over]: '1.6931471805599454'\n",
      "Column [quick]: '1.6931471805599454'\n",
      "Column [the]: '1.0'\n"
     ]
    }
   ],
   "source": [
    "#Display IDF values\n",
    "for ele1, ele2 in zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_):\n",
    "    print(f\"Column [{ele1}]: '{ele2}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b2b0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index [0]: 'brown'\n",
      "Index [1]: 'chased'\n",
      "Index [2]: 'dog'\n",
      "Index [3]: 'fox'\n",
      "Index [4]: 'is'\n",
      "Index [5]: 'jumps'\n",
      "Index [6]: 'lazy'\n",
      "Index [7]: 'over'\n",
      "Index [8]: 'quick'\n",
      "Index [9]: 'the'\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(tfidf_vectorizer.get_feature_names_out()):\n",
    "    print(f\"Index [{i}]: '{name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_query = ' '.join(tokenized_query)\n",
    "preprocessed_query\n",
    "lst = [preprocessed_query]\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e58654c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78980693, 0.        , 0.61335554, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_query = tfidf_vectorizer.transform(lst)\n",
    "tfidf_query.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a48d204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index [0]: 'brown'\n",
      "Index [1]: 'chased'\n",
      "Index [2]: 'dog'\n",
      "Index [3]: 'fox'\n",
      "Index [4]: 'is'\n",
      "Index [5]: 'jumps'\n",
      "Index [6]: 'lazy'\n",
      "Index [7]: 'over'\n",
      "Index [8]: 'quick'\n",
      "Index [9]: 'the'\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(tfidf_vectorizer.get_feature_names_out()):\n",
    "    print(f\"Index [{i}]: '{name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e13333",
   "metadata": {},
   "source": [
    "### Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83bb036b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37829253, 0.5699431 , 0.24011886]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosin_similarity = cosine_similarity(tfidf_query, tfidf_matrix)\n",
    "cosin_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41efa6",
   "metadata": {},
   "source": [
    "### Rank documents by similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "113d81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [(documents[i], cosin_similarity[0][i]) for i in range(len(documents))]\n",
    "results.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "181d4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.57\n",
      "A brown dog chased the fox.\n",
      "\n",
      "Similarity: 0.38\n",
      "The quick brown fox jumps over the lazy dog.\n",
      "\n",
      "Similarity: 0.24\n",
      "The dog is lazy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc, similarity in results:\n",
    "    print(f\"Similarity: {similarity:.2f}\\n{doc}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
